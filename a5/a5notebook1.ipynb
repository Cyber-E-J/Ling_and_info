{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "872722794e74995476ee2a693a88e5ba",
     "grade": false,
     "grade_id": "cell-05fb407e20c068e6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Assignment 5: \"No one can be told what the Ranktrix is. You have to see it for yourself.\"\n",
    "\n",
    "## Â© Cristian Danescu-Niculescu-Mizil 2023\n",
    "\n",
    "## CS/INFO 4300 Language and Information\n",
    "\n",
    "### Due by 11:59PM on Friday March 03, 2023\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "For code completion tasks, just type your code after the comment marking the place.  For questions, use as many notebook cells as needed to compute intermediate stuff.\n",
    "\n",
    "You are strongly encouraged to write sensible **test cases** for your code.\n",
    "\n",
    "This is an **individual** assignment.\n",
    "\n",
    "If you use any outside sources (e.g. research papers, StackOverflow) please list your sources.\n",
    "\n",
    "In this assignment we will explore evaluation of an information retrevial system where both queries and results are movies. Ever wanted to know what the most similar movie to \"The Matrix\" is, in terms of language? Now is your chance! You take the blue pill - the story ends, you wake up in your dorm on west campus and believe whatever you want to believe. You take the red pill - you stay in CS/INFO 4300 and we show you how deep the rabbit-hole goes.\n",
    "\n",
    "**Guidelines**\n",
    "\n",
    "* All cells that contain the blocks that read `# YOUR CODE HERE` are editable and are to be completed to ensure you pass the test-cases. Make sure to write your code where indicated.\n",
    "\n",
    "* All cells that read `YOUR ANSWER HERE` are free-response cells that are editable and are to be completed.\n",
    "\n",
    "* Please delete raise `NotImplementedError()` after filling in the function code. It is only meant to be a temporary placeholder\n",
    "\n",
    "* You may use any number of notebook cells to explore the data and test out your functions, although you will only be graded on the solution itself.\n",
    "\n",
    "* You are unable to modify the read-only cells.\n",
    "\n",
    "* You should also use Markdown cells to explain your code and discuss your results when necessary.\n",
    "Instructions can be found [here](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "* All floating point values should be printed with **2 decimal places** precision. You can do so using the built-in round function.\n",
    "\n",
    "* **Never delete any code / free response and autograder test cell.**\n",
    "\n",
    "* Do not delete the cells for optional questions, even if you do not choose to answer them.\n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "This project aims to help you get comfortable working with the following tools / technologies / concepts:\n",
    "\n",
    "* TF-IDF vectorization using sklearn\n",
    "* Similarity matrices\n",
    "* Precision & Recall\n",
    "* Cosine similarity vs Jaccard similarity\n",
    "* Rocchio Algorithm\n",
    "\n",
    "**Grading**\n",
    "\n",
    "For code-completion questions you will be graded on passing the public test cases we have included, as well as any hidden test cases that we have supplemented to ensure that your logic is correct.\n",
    "\n",
    "For free-response questions you will be manually graded on the quality of your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "558664013aacfecb74ff70f3962fb2c3",
     "grade": false,
     "grade_id": "cell-85960141460df3c1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Introduction\n",
    "In this assignment, we will be building a system that allows you to query for movies similar to a given movie. Unlike before, queries and information retrieved have the same type -- i.e. movies are *both* queries and results. To accomplish this task, we will utilize a dataset of movies and their transcripts. We will begin by using the language contained in the transcripts to do basic queries. We will continue to use the vector space model, encoding \"documents\" (here, a document is a movie script) as tf-idf vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "549462241d79ceaf535efdc9cd232e18",
     "grade": false,
     "grade_id": "cell-409acf73e9b10d87",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import json\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba8a0388b2a197569416528c72f70425",
     "grade": false,
     "grade_id": "cell-12fdde1aa8750596",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Using sklearn to get tf-idf vectors\n",
    "On the last assignment, we used an inverted index to quickly compute queries by taking advantage of the sparsity of tf-idf vectors in our vector space. However, the dataset we are considering for this assignment is small enough such that we can use explicit vectors, rather than an inverted index, to compute cosine similarities. We also will not be implementing tf-idf by hand -- we will be using an existing implementation from the library [sklearn,](http://scikit-learn.org/stable/) which provides a lot of good implementations of machine learning algorithms in python. We will be making heavy use of this powerful library later in the semester, so using it to extract tfidf features is a good starting point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8f1970974d230c84ae14b2424042b3b",
     "grade": false,
     "grade_id": "cell-6563bc55c31b7968",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 617 movie transcripts\n",
      "Each movie transcript is a dictionary with the following keys...\n",
      "dict_keys(['movie_name', 'movie_id', 'categories', 'script'])\n",
      "The index of \"spare me\" is 7\n"
     ]
    }
   ],
   "source": [
    "with open(\"movie_scripts_data.json\") as f:\n",
    "    data = json.loads(f.readlines()[0])\n",
    "num_movies = len(data)\n",
    "print(\"Loaded {} movie transcripts\".format(num_movies))\n",
    "print(\"Each movie transcript is a dictionary with the following keys...\")\n",
    "print(data[0].keys())\n",
    "\n",
    "# Here, we will assign an index for each movie_id. This index will help us access data in numpy matrices.\n",
    "movie_id_to_index = {movie_id:index for index, movie_id in enumerate([d['movie_id'] for d in data])}\n",
    "\n",
    "# We will also need a dictionary maping movie names to movie ids\n",
    "movie_name_to_id = {name:mid for name, mid in zip([d['movie_name'] for d in data],\n",
    "                                                     [d['movie_id'] for d in data])}\n",
    "movie_id_to_name = {v:k for k,v in movie_name_to_id.items()}\n",
    "\n",
    "# and because it might be useful...\n",
    "movie_name_to_index = {name:movie_id_to_index[movie_name_to_id[name]] for name in [d['movie_name'] for d in data]}\n",
    "movie_index_to_name = {v:k for k,v in movie_name_to_index.items()}\n",
    "\n",
    "movie_names = [name for name in [d['movie_name'] for d in data]]\n",
    "\n",
    "print(\"The index of \\\"{}\\\" is {}\".format(data[7]['movie_name'], movie_id_to_index[data[7]['movie_id']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8122747da17e52a4f657d5607e14a321",
     "grade": false,
     "grade_id": "cell-081a2217d72930ff",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We can see that each movie is assigned an \"index\" (from 0 to 616). These will correspond to the rows of a document-by-tfidf score matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b6ebed4f269748f249b051b2266ab63f",
     "grade": false,
     "grade_id": "cell-414c5e6624055e75",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 1 (Code Completion): TFIDF Vectorizer\n",
    "Read up on sklearn's [tfidf-vectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). This function takes in a list of documents and some parameters related to parsing and outputs a document-by-vocabulary matrix, where entry i,j corresponds to the tfidf score of word j in document i. \n",
    "\n",
    "Your first job is to make a TfidfVectorizer object that includes the following preprocessing properties (look at the documentation to learn how to achieve these): \n",
    "- It only considers words that appear in _at least_ ten documents, but in _no more_ than 80% of all documents.\n",
    "- It computes a maximum of 5000 features, and detects and filters out stopwords in English.\n",
    "- It should normalize all tfidf vectors to have an l2 norm of 1.\n",
    "\n",
    "Once you've made this object, call its `fit_transform()` function on the list of *scripts* (not titles) in data. This should produce a numpy matrix whose shape is the number of documents by the number of words you're considering (which has a maximum of 5000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f8e5ed7dca8e416a8f30c691410cb8c",
     "grade": false,
     "grade_id": "build_doc_by_vocab",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "n_feats = 5000\n",
    "doc_by_vocab = np.empty([len(data), n_feats])\n",
    "\n",
    "def build_vectorizer(max_features, stop_words, max_df=0.8, min_df=10, norm='l2'):\n",
    "    \"\"\"Returns a TfidfVectorizer object with the above preprocessing properties.\n",
    "    \n",
    "    Note: This function may log a deprecation warning. This is normal, and you\n",
    "    can simply ignore it.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    max_features : int\n",
    "        Corresponds to 'max_features' parameter of the sklearn TfidfVectorizer \n",
    "        constructer.\n",
    "    stop_words : str\n",
    "        Corresponds to 'stop_words' parameter of the sklearn TfidfVectorizer constructer. \n",
    "    max_df : float\n",
    "        Corresponds to 'max_df' parameter of the sklearn TfidfVectorizer constructer. \n",
    "    min_df : float\n",
    "        Corresponds to 'min_df' parameter of the sklearn TfidfVectorizer constructer. \n",
    "    norm : str\n",
    "        Corresponds to 'norm' parameter of the sklearn TfidfVectorizer constructer. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    TfidfVectorizer\n",
    "        A TfidfVectorizer object with the given parameters as its preprocessing properties.\n",
    "    \"\"\"\n",
    "    return TfidfVectorizer(max_features=max_features, stop_words=stop_words, max_df=max_df, min_df=min_df, norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c864ba21d6163ac4daee3cee331c8aa",
     "grade": false,
     "grade_id": "cell-86320f51d83cfd9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vec = build_vectorizer(n_feats, \"english\")\n",
    "doc_by_vocab = tfidf_vec.fit_transform([d['script'] for d in data]).toarray()\n",
    "index_to_vocab = {i:v for i, v in enumerate(tfidf_vec.get_feature_names())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8063bf0b026ef16ac0b031af81dd29dd",
     "grade": true,
     "grade_id": "build_doc_by_vocab_test",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is an autograder test. Here we can test the function you just wrote above.\n",
    "\"\"\"Check that build_vectorizer returns the correct output\"\"\"\n",
    "assert type(doc_by_vocab) == np.ndarray\n",
    "assert type(tfidf_vec) == TfidfVectorizer\n",
    "assert sum(doc_by_vocab[2,:]) < 20\n",
    "assert doc_by_vocab.shape == (617, 5000)\n",
    "assert 'zoo' in index_to_vocab.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "836aff0bda837eb8517486cd2504da1a",
     "grade": false,
     "grade_id": "cell-44503d2b6b03160a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 2 (Code Completion): Cosine Similarity\n",
    "You will implement the function below which takes in the names of two movies, a term-document matrix of movie transcripts, and a dictionary that maps movie names to the corresponding row index in the term-document matrix.\n",
    "\n",
    "Remember that cosine similarity is defined as:\n",
    "\n",
    "$$ cossim(\\vec{q}, \\vec{d_j}) = \\frac{\\vec{q} \\cdot \\vec{d_j}}{\\|\\vec{q}\\| \\cdot \\|\\vec{d_j}\\|}$$\n",
    "\n",
    "\n",
    "Hint: As always, make good use of numpy to make your implementation efficient, as this method will be called in later questions. However, note that you cannot import off-the-shelf implementation of cosine similarity for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1b73baf1d838505841a62f69cbf82f1",
     "grade": false,
     "grade_id": "get_sim",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_sim(mov1, mov2, input_doc_mat, input_movie_name_to_index):\n",
    "    \"\"\"Returns a float giving the cosine similarity of \n",
    "       the two movie transcripts.\n",
    "    \n",
    "    Params: {mov1 (str): Name of the first movie.\n",
    "             mov2 (str): Name of the second movie.\n",
    "             input_doc_mat (numpy.ndarray): Term-document matrix of movie transcripts, where \n",
    "                    each row represents a document (movie transcript) and each column represents a term.\n",
    "             movie_name_to_index (dict): Dictionary that maps movie names to the corresponding row index \n",
    "                    in the term-document matrix.}\n",
    "    Returns: Float (Cosine similarity of the two movie transcripts.)\n",
    "    \"\"\"\n",
    "    # Get the row index of mov1 and mov2 in the term-document matrix\n",
    "    mov1_idx = input_movie_name_to_index[mov1]\n",
    "    mov2_idx = input_movie_name_to_index[mov2]\n",
    "\n",
    "    # Get the vector representations of mov1 and mov2\n",
    "    mov1_vec = input_doc_mat[mov1_idx]\n",
    "    mov2_vec = input_doc_mat[mov2_idx]\n",
    "\n",
    "    # Compute the cosine similarity between mov1 and mov2\n",
    "    cos_sim = np.dot(mov1_vec, mov2_vec) / (LA.norm(mov1_vec) * LA.norm(mov2_vec))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7440ea8da380431e2367bad91e1cdeeb",
     "grade": true,
     "grade_id": "get_sim_test",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: Star Wars vs. Jurassic Park\n",
      "======\n",
      "0.06579339531549763\n",
      "\n",
      "Similarity: Star Wars vs. Star Trek: Generations\n",
      "======\n",
      "0.21443120458852558\n"
     ]
    }
   ],
   "source": [
    "# This is an autograder test. Here we can test the function you just wrote above.\n",
    "\"\"\"Check that get_sim returns the correct output\"\"\"\n",
    "print(\"Similarity: Star Wars vs. Jurassic Park\")\n",
    "print(\"======\")\n",
    "test1 = get_sim('star wars', 'jurassic park', doc_by_vocab, movie_name_to_index)\n",
    "print(test1)\n",
    "assert test1 < 0.07 and test1 > 0.06\n",
    "print(\"\")\n",
    "\n",
    "print(\"Similarity: Star Wars vs. Star Trek: Generations\")\n",
    "print(\"======\")\n",
    "test2 = get_sim('star wars', 'star trek: generations', doc_by_vocab, movie_name_to_index)\n",
    "print(test2)\n",
    "assert test2 < 0.25 and test2 > 0.20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_by_vocab[0]\n",
    "doc_by_vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_prod = doc_by_vocab[0] * doc_by_vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\"murderland\"': 53,\n",
       " '10 things i hate about you': 89,\n",
       " '1492: conquest of paradise': 88,\n",
       " '15 minutes': 91,\n",
       " '2001: a space odyssey': 90,\n",
       " '48 hrs.': 85,\n",
       " '8mm': 87,\n",
       " 'a bucket of blood': 15,\n",
       " 'a clockwork orange': 426,\n",
       " \"a hard day's night\": 315,\n",
       " 'a nightmare on elm street': 80,\n",
       " 'a nightmare on elm street 3: dream warriors': 569,\n",
       " 'a nightmare on elm street 4: the dream master': 86,\n",
       " \"a nightmare on elm street part 2: freddy's revenge\": 570,\n",
       " 'a nightmare on elm street: the dream child': 93,\n",
       " 'a walk to remember': 186,\n",
       " 'affliction': 410,\n",
       " 'agnes of god': 314,\n",
       " 'air force one': 409,\n",
       " 'airplane ii: the sequel': 412,\n",
       " 'airplane!': 411,\n",
       " 'alien': 316,\n",
       " 'alien nation': 414,\n",
       " 'alien vs. predator': 317,\n",
       " 'aliens': 413,\n",
       " 'all about eve': 612,\n",
       " \"all the president's men\": 613,\n",
       " 'amadeus': 416,\n",
       " 'american madness': 418,\n",
       " 'american outlaws': 417,\n",
       " 'american pie': 127,\n",
       " 'american psycho': 242,\n",
       " 'an american werewolf in london': 415,\n",
       " 'an american werewolf in paris': 126,\n",
       " 'an officer and a gentleman': 293,\n",
       " 'anastasia': 192,\n",
       " 'annie hall': 190,\n",
       " 'antitrust': 243,\n",
       " 'antz': 122,\n",
       " 'apocalypse now': 124,\n",
       " 'arcade': 48,\n",
       " 'arctic blue': 135,\n",
       " 'as good as it gets': 196,\n",
       " 'assassins': 551,\n",
       " 'asylum': 552,\n",
       " 'austin powers: international man of mystery': 244,\n",
       " 'bachelor party': 238,\n",
       " 'back to the future': 187,\n",
       " 'backdraft': 239,\n",
       " 'bad lieutenant': 240,\n",
       " 'badlands': 555,\n",
       " 'bamboozled': 241,\n",
       " 'barry lyndon': 236,\n",
       " 'barton fink': 553,\n",
       " 'basic': 237,\n",
       " 'basic instinct': 554,\n",
       " 'basquiat': 547,\n",
       " 'batman': 393,\n",
       " 'batman and robin': 395,\n",
       " 'batman forever': 394,\n",
       " 'batman returns': 548,\n",
       " 'bean': 392,\n",
       " 'beavis and butt-head do america': 391,\n",
       " 'beetle juice': 390,\n",
       " 'being john malkovich': 388,\n",
       " 'being there': 389,\n",
       " 'beloved': 387,\n",
       " 'big fish': 43,\n",
       " 'birthday girl': 42,\n",
       " 'black rain': 40,\n",
       " 'black snake moan': 41,\n",
       " 'blade': 208,\n",
       " 'blade ii': 207,\n",
       " 'blade runner': 39,\n",
       " 'blast from the past': 38,\n",
       " 'blood simple.': 202,\n",
       " 'bloodmoon': 203,\n",
       " 'blow': 204,\n",
       " 'blue velvet': 37,\n",
       " 'body of evidence': 200,\n",
       " 'bones': 9,\n",
       " 'book of shadows: blair witch 2': 209,\n",
       " 'bottle rocket': 35,\n",
       " 'bound': 8,\n",
       " 'braveheart': 508,\n",
       " 'brazil': 10,\n",
       " 'bringing out the dead': 13,\n",
       " 'broadcast news': 12,\n",
       " 'buffy the vampire slayer': 14,\n",
       " 'bull durham': 17,\n",
       " 'casablanca': 506,\n",
       " 'casino': 16,\n",
       " 'cast away': 507,\n",
       " 'catwoman': 474,\n",
       " 'cellular': 475,\n",
       " 'charade': 473,\n",
       " 'cherry falls': 470,\n",
       " 'chill factor': 471,\n",
       " 'chinatown': 468,\n",
       " 'citizen kane': 482,\n",
       " 'clerks.': 483,\n",
       " 'cliffhanger': 425,\n",
       " 'collateral': 427,\n",
       " 'confidence': 513,\n",
       " 'conspiracy theory': 428,\n",
       " 'contact': 429,\n",
       " 'cool hand luke': 430,\n",
       " 'copycat': 431,\n",
       " 'crash': 432,\n",
       " 'crazy love': 433,\n",
       " 'crime spree': 434,\n",
       " 'crouching tiger, hidden dragon': 575,\n",
       " 'croupier': 510,\n",
       " 'cruel intentions': 573,\n",
       " 'dark angel': 504,\n",
       " 'dark city': 578,\n",
       " 'dark star': 511,\n",
       " 'dave': 577,\n",
       " 'day of the dead': 576,\n",
       " 'dead poets society': 581,\n",
       " 'deep rising': 580,\n",
       " 'demolition man': 137,\n",
       " 'detroit rock city': 505,\n",
       " 'die hard': 197,\n",
       " 'do the right thing': 130,\n",
       " 'dog day afternoon': 132,\n",
       " 'domino': 133,\n",
       " 'donnie darko': 347,\n",
       " 'dr. strangelove or: how i learned to stop worrying and love the bomb': 599,\n",
       " 'drop dead gorgeous': 346,\n",
       " 'duck soup': 349,\n",
       " 'dumb and dumberer: when harry met lloyd': 131,\n",
       " 'dune': 128,\n",
       " 'ed wood': 129,\n",
       " 'edtv': 319,\n",
       " 'election': 318,\n",
       " 'enemy of the state': 320,\n",
       " 'entrapment': 322,\n",
       " 'erik the viking': 343,\n",
       " 'erin brockovich': 325,\n",
       " 'escape from l.a.': 310,\n",
       " 'escape from the planet of the apes': 311,\n",
       " 'eternal sunshine of the spotless mind': 342,\n",
       " 'even cowgirls get the blues': 345,\n",
       " 'event horizon': 344,\n",
       " 'excalibur': 306,\n",
       " 'face/off': 309,\n",
       " 'fantastic four': 352,\n",
       " 'fantastic voyage': 304,\n",
       " 'fargo': 305,\n",
       " 'fast times at ridgemont high': 351,\n",
       " 'fear and loathing in las vegas': 154,\n",
       " 'feast': 155,\n",
       " 'fight club': 300,\n",
       " 'final destination': 380,\n",
       " 'final destination 2': 301,\n",
       " 'five easy pieces': 480,\n",
       " 'five feet high and rising': 479,\n",
       " 'fletch': 478,\n",
       " 'frances': 156,\n",
       " 'frankenstein': 157,\n",
       " 'freddy vs. jason': 407,\n",
       " 'frequency': 350,\n",
       " 'friday the 13th': 158,\n",
       " 'friday the 13th part iii': 396,\n",
       " 'friday the 13th part viii: jason takes manhattan': 52,\n",
       " 'from dusk till dawn': 159,\n",
       " 'g.i. jane': 160,\n",
       " 'galaxy quest': 162,\n",
       " 'game 6': 64,\n",
       " 'gandhi': 22,\n",
       " 'gattaca': 23,\n",
       " 'george washington': 163,\n",
       " 'get carter': 21,\n",
       " 'get shorty': 605,\n",
       " 'ghost ship': 604,\n",
       " 'ghost world': 603,\n",
       " 'ghostbusters': 608,\n",
       " 'ghostbusters ii': 609,\n",
       " 'gladiator': 607,\n",
       " 'glengarry glen ross': 117,\n",
       " 'gods and monsters': 251,\n",
       " 'godzilla': 161,\n",
       " 'gone in sixty seconds': 250,\n",
       " 'good will hunting': 252,\n",
       " 'goodfellas': 253,\n",
       " 'grand hotel': 611,\n",
       " 'grosse pointe blank': 246,\n",
       " 'hackers': 248,\n",
       " 'halloween': 258,\n",
       " 'halloween 4: the return of michael myers': 259,\n",
       " 'halloween h20: 20 years later': 103,\n",
       " 'halloween iii: season of the witch': 118,\n",
       " 'halloween: the curse of michael myers': 104,\n",
       " 'hannah and her sisters': 228,\n",
       " 'hannibal': 229,\n",
       " 'happy birthday, wanda june': 101,\n",
       " 'happy campers': 230,\n",
       " 'hardcore': 102,\n",
       " 'harold and maude': 99,\n",
       " 'heathers': 231,\n",
       " 'heavenly creatures': 232,\n",
       " 'hellbound: hellraiser ii': 100,\n",
       " 'hellboy': 97,\n",
       " 'hellraiser': 98,\n",
       " 'hellraiser iii: hell on earth': 531,\n",
       " 'hellraiser: hellseeker': 233,\n",
       " 'hero': 234,\n",
       " 'hider in the house': 235,\n",
       " 'high fidelity': 95,\n",
       " 'highlander': 96,\n",
       " 'highlander iii: the sorcerer': 225,\n",
       " 'his girl friday': 550,\n",
       " 'hope and glory': 549,\n",
       " 'hostage': 226,\n",
       " 'hotel rwanda': 420,\n",
       " 'house of 1000 corpses': 189,\n",
       " 'house of the damned': 537,\n",
       " 'house on haunted hill': 419,\n",
       " 'hudson hawk': 424,\n",
       " 'human nature': 188,\n",
       " 'i am legend': 191,\n",
       " 'i still know what you did last summer': 568,\n",
       " 'i walked with a zombie': 422,\n",
       " 'independence day': 194,\n",
       " 'indiana jones and the last crusade': 546,\n",
       " 'indiana jones and the temple of doom': 545,\n",
       " 'innerspace': 584,\n",
       " 'insomnia': 517,\n",
       " 'interview with the vampire: the vampire chronicles': 615,\n",
       " 'intolerable cruelty': 582,\n",
       " 'invaders from mars': 195,\n",
       " 'isle of the dead': 567,\n",
       " 'it happened one night': 583,\n",
       " \"it's a wonderful life\": 566,\n",
       " 'jackie brown': 589,\n",
       " \"jacob's ladder\": 586,\n",
       " 'jason goes to hell: the final friday': 19,\n",
       " 'jason lives: friday the 13th part vi': 18,\n",
       " 'jason x': 587,\n",
       " 'jaws': 590,\n",
       " 'jaws 2': 565,\n",
       " 'jaws 3-d': 564,\n",
       " 'jaws: the revenge': 563,\n",
       " 'jennifer eight': 561,\n",
       " 'jerry maguire': 560,\n",
       " 'jfk': 588,\n",
       " 'juno': 591,\n",
       " 'jurassic park': 406,\n",
       " 'jurassic park iii': 559,\n",
       " 'kafka': 408,\n",
       " 'kalifornia': 151,\n",
       " 'kids': 150,\n",
       " 'king kong': 401,\n",
       " 'klute': 402,\n",
       " 'knight moves': 153,\n",
       " 'kramer vs. kramer': 403,\n",
       " 'krull': 152,\n",
       " 'kundun': 404,\n",
       " \"l'avventura\": 313,\n",
       " 'l.a. confidential': 321,\n",
       " 'la battaglia di algeri': 205,\n",
       " 'labor of love': 146,\n",
       " 'lake placid': 399,\n",
       " 'last of the mohicans': 358,\n",
       " 'le grand bleu': 3,\n",
       " 'leaving las vegas': 149,\n",
       " 'legally blonde': 148,\n",
       " 'legend': 143,\n",
       " 'leviathan': 357,\n",
       " 'life as a house': 142,\n",
       " 'little nicky': 267,\n",
       " 'lock, stock and two smoking barrels': 360,\n",
       " \"logan's run\": 268,\n",
       " 'lone star': 359,\n",
       " 'lord of illusions': 354,\n",
       " 'lost highway': 269,\n",
       " 'lost horizon': 262,\n",
       " 'lost in translation': 353,\n",
       " 'lost souls': 356,\n",
       " 'love & basketball': 355,\n",
       " 'lÃ©on': 147,\n",
       " 'made': 265,\n",
       " 'magnolia': 366,\n",
       " 'malcolm x': 270,\n",
       " 'man on fire': 271,\n",
       " 'man on the moon': 112,\n",
       " 'manhunt': 114,\n",
       " 'manhunter': 115,\n",
       " 'maniac': 455,\n",
       " 'marty': 448,\n",
       " 'mash': 447,\n",
       " 'meet joe black': 119,\n",
       " 'meet john doe': 446,\n",
       " 'memento': 116,\n",
       " 'men in black': 263,\n",
       " 'metro': 445,\n",
       " 'metropolis': 444,\n",
       " 'miami vice': 2,\n",
       " 'midnight cowboy': 110,\n",
       " 'midnight express': 111,\n",
       " 'mighty morphin power rangers': 443,\n",
       " 'mimic': 47,\n",
       " 'minority report': 264,\n",
       " 'misery': 46,\n",
       " 'mission: impossible': 44,\n",
       " 'mission: impossible ii': 45,\n",
       " 'mobsters': 442,\n",
       " 'monkeybone': 441,\n",
       " 'monty python and the holy grail': 50,\n",
       " 'moonstruck': 51,\n",
       " 'mr. deeds goes to town': 78,\n",
       " 'mr. smith goes to washington': 449,\n",
       " 'mrs brown': 49,\n",
       " 'mulholland dr.': 54,\n",
       " 'mumford': 79,\n",
       " \"my best friend's wedding\": 516,\n",
       " 'my girl': 515,\n",
       " 'my girl 2': 514,\n",
       " \"my mother dreams the satan's disciples in new york\": 450,\n",
       " 'mystery men': 77,\n",
       " 'mystery of the wax museum': 453,\n",
       " 'napoleon': 74,\n",
       " 'nashville': 542,\n",
       " 'natural born killers': 518,\n",
       " 'neuromancer': 521,\n",
       " 'never been kissed': 522,\n",
       " 'new nightmare': 488,\n",
       " 'next friday': 75,\n",
       " 'nick of time': 72,\n",
       " 'ninotchka': 81,\n",
       " 'nixon': 289,\n",
       " 'no country for old men': 288,\n",
       " 'nothing but a man': 519,\n",
       " 'notting hill': 436,\n",
       " 'nuovo cinema paradiso': 469,\n",
       " 'nurse betty': 291,\n",
       " 'o brother, where art thou?': 290,\n",
       " 'on the waterfront': 437,\n",
       " \"one flew over the cuckoo's nest\": 435,\n",
       " 'only you': 438,\n",
       " 'orgy of the dead': 440,\n",
       " 'out of sight': 439,\n",
       " 'panic room': 292,\n",
       " 'panther': 295,\n",
       " 'pearl harbor': 558,\n",
       " 'peggy sue got married': 557,\n",
       " 'pet sematary': 297,\n",
       " 'pet sematary ii': 260,\n",
       " 'philadelphia': 261,\n",
       " 'pirates of the caribbean': 296,\n",
       " 'pitch black': 299,\n",
       " 'planet of the apes': 164,\n",
       " 'plastic man': 334,\n",
       " 'platinum blonde': 335,\n",
       " 'platoon': 256,\n",
       " 'playback': 257,\n",
       " 'pleasantville': 336,\n",
       " 'point break': 255,\n",
       " 'predator': 385,\n",
       " 'pretty woman': 224,\n",
       " 'psycho': 456,\n",
       " 'punch-drunk love': 337,\n",
       " 'quantum project': 452,\n",
       " 'quills': 338,\n",
       " 'raging bull': 340,\n",
       " 'rambling rose': 451,\n",
       " 'rambo: first blood part ii': 374,\n",
       " 'rear window': 341,\n",
       " 'rebel without a cause': 326,\n",
       " 'red white black & blue': 466,\n",
       " 'reindeer games': 327,\n",
       " 'reservoir dogs': 499,\n",
       " 'rko 281': 339,\n",
       " 'rocky': 277,\n",
       " 'romeo and juliet': 279,\n",
       " 'ronin': 272,\n",
       " 'roughshod': 498,\n",
       " 'route 9': 273,\n",
       " 'runaway bride': 284,\n",
       " 'rush hour': 275,\n",
       " 'rush hour 2': 274,\n",
       " 'salt of the earth': 144,\n",
       " 'saving private ryan': 210,\n",
       " 'say anything...': 211,\n",
       " 'scary movie 2': 497,\n",
       " \"schindler's list\": 140,\n",
       " 'scream': 139,\n",
       " 'scream 2': 141,\n",
       " 'scream 3': 138,\n",
       " 'serial mom': 496,\n",
       " 'seven': 227,\n",
       " 'seven days to live': 1,\n",
       " 'sex, lies, and videotape': 502,\n",
       " 'shakespeare in love': 0,\n",
       " 'shallow grave': 329,\n",
       " 'shampoo': 328,\n",
       " 'shivers': 501,\n",
       " 'shock treatment': 500,\n",
       " 'sideways': 495,\n",
       " 'signs': 494,\n",
       " 'silver bullet': 330,\n",
       " 'silverado': 169,\n",
       " 'simone': 170,\n",
       " 'sister act': 333,\n",
       " 'slash': 168,\n",
       " 'sleepless in seattle': 285,\n",
       " 'sleepy hollow': 332,\n",
       " 'sling blade': 6,\n",
       " 'slither': 173,\n",
       " 'smoke': 4,\n",
       " 'smokey and the bandit': 174,\n",
       " \"smokin' aces\": 171,\n",
       " 'snow falling on cedars': 459,\n",
       " 'solaris': 172,\n",
       " 'soldier': 460,\n",
       " 'some like it hot': 461,\n",
       " 'someone to watch over me': 165,\n",
       " 'sounder': 463,\n",
       " 'south park: bigger longer & uncut': 464,\n",
       " 'spacejacked': 5,\n",
       " 'spare me': 7,\n",
       " 'sphere': 614,\n",
       " 'spider-man': 166,\n",
       " 'stalag 17': 69,\n",
       " 'star trek iii: the search for spock': 71,\n",
       " 'star trek iv: the voyage home': 56,\n",
       " 'star trek v: the final frontier': 108,\n",
       " 'star trek vi: the undiscovered country': 57,\n",
       " 'star trek: first contact': 61,\n",
       " 'star trek: generations': 66,\n",
       " 'star trek: insurrection': 55,\n",
       " 'star trek: nemesis': 83,\n",
       " 'star trek: the motion picture': 596,\n",
       " 'star trek: the wrath of khan': 70,\n",
       " 'star wars': 616,\n",
       " 'star wars: episode vi - return of the jedi': 465,\n",
       " 'star wars: the empire strikes back': 324,\n",
       " 'starman': 82,\n",
       " 'starship troopers': 597,\n",
       " 'state and main': 595,\n",
       " 'stepmom': 594,\n",
       " 'storytelling': 601,\n",
       " 'strange days': 217,\n",
       " 'stranglehold': 600,\n",
       " 'suburbia': 598,\n",
       " 'sugar & spice': 593,\n",
       " 'sunset blvd.': 592,\n",
       " 'supergirl': 60,\n",
       " 'superman': 298,\n",
       " 'superman ii': 58,\n",
       " 'superman iii': 398,\n",
       " 'superman iv: the quest for peace': 59,\n",
       " 'suspect zero': 216,\n",
       " 'sweet smell of success': 62,\n",
       " 'swingers': 219,\n",
       " 'taking sides': 67,\n",
       " 'taxi driver': 220,\n",
       " 'terminator 2: judgment day': 63,\n",
       " 'the abyss': 312,\n",
       " 'the adventures of buckaroo banzai across the 8th dimension': 556,\n",
       " 'the adventures of ford fairlane': 477,\n",
       " 'the anniversary party': 123,\n",
       " 'the apartment': 125,\n",
       " 'the atomic submarine': 92,\n",
       " 'the avengers': 245,\n",
       " 'the beach': 198,\n",
       " 'the believer': 373,\n",
       " 'the big lebowski': 386,\n",
       " 'the birds': 215,\n",
       " 'the black dahlia': 206,\n",
       " 'the body snatcher': 214,\n",
       " 'the boondock saints': 36,\n",
       " 'the bourne identity': 11,\n",
       " 'the bourne supremacy': 34,\n",
       " 'the bridges of madison county': 201,\n",
       " 'the butterfly effect': 509,\n",
       " 'the cell': 282,\n",
       " 'the cider house rules': 512,\n",
       " 'the crow': 574,\n",
       " 'the crow: salvation': 32,\n",
       " 'the crying game': 472,\n",
       " 'the curse': 579,\n",
       " 'the curse of the cat people': 572,\n",
       " 'the day the earth stood still': 33,\n",
       " 'the deer hunter': 136,\n",
       " 'the devil and daniel webster': 134,\n",
       " 'the elephant man': 348,\n",
       " 'the english patient': 323,\n",
       " 'the exorcist': 307,\n",
       " 'the fabulous baker boys': 308,\n",
       " 'the family man': 302,\n",
       " 'the fantastic four': 303,\n",
       " 'the fifth element': 84,\n",
       " 'the fisher king': 481,\n",
       " 'the french connection': 476,\n",
       " 'the game': 213,\n",
       " 'the getaway': 20,\n",
       " 'the ghost and the darkness': 602,\n",
       " 'the godfather': 218,\n",
       " 'the godfather: part ii': 120,\n",
       " 'the graduate': 606,\n",
       " 'the grapes of wrath': 247,\n",
       " 'the grifters': 610,\n",
       " 'the haunting': 212,\n",
       " 'the hebrew hammer': 375,\n",
       " 'the horse whisperer': 249,\n",
       " 'the hudsucker proxy': 423,\n",
       " 'the hustler': 193,\n",
       " 'the ice storm': 421,\n",
       " 'the insider': 585,\n",
       " 'the jacket': 29,\n",
       " 'the jazz singer': 562,\n",
       " 'the leopard man': 376,\n",
       " 'the life of david gale': 266,\n",
       " 'the limey': 287,\n",
       " 'the lost boys': 30,\n",
       " 'the lost son': 369,\n",
       " 'the lost world: jurassic park': 405,\n",
       " 'the magic toyshop': 367,\n",
       " 'the majestic': 222,\n",
       " 'the man in the iron mask': 365,\n",
       " \"the man who wasn't there\": 286,\n",
       " 'the matrix': 113,\n",
       " 'the messenger': 370,\n",
       " 'the mummy': 76,\n",
       " 'the negotiator': 520,\n",
       " 'the night of the hunter': 73,\n",
       " 'the nightmare before christmas': 523,\n",
       " 'the patriot': 294,\n",
       " 'the pianist': 371,\n",
       " 'the piano': 372,\n",
       " \"the ploughman's lunch\": 254,\n",
       " 'the princess bride': 458,\n",
       " 'the producers': 457,\n",
       " 'the relic': 281,\n",
       " 'the rock': 223,\n",
       " 'the rocky horror picture show': 276,\n",
       " 'the salton sea': 145,\n",
       " 'the searchers': 397,\n",
       " 'the seventh victim': 503,\n",
       " 'the shining': 331,\n",
       " 'the silence of the lambs': 400,\n",
       " 'the sixth sense': 167,\n",
       " 'the sting': 381,\n",
       " 'the sweet hereafter': 65,\n",
       " 'the talented mr. ripley': 221,\n",
       " 'the terminator': 68,\n",
       " 'the thin man': 382,\n",
       " 'the thing': 31,\n",
       " 'the third man': 199,\n",
       " 'the time machine': 28,\n",
       " 'the truman show': 280,\n",
       " 'the usual suspects': 525,\n",
       " 'the verdict': 490,\n",
       " 'the war of the worlds': 489,\n",
       " 'the wedding date': 462,\n",
       " 'the witching hour': 383,\n",
       " 'the wizard of oz': 178,\n",
       " 'the woodsman': 105,\n",
       " 'the world is not enough': 179,\n",
       " 'the x files': 283,\n",
       " 'thelma & louise': 26,\n",
       " \"there's something about mary\": 27,\n",
       " 'thirteen days': 24,\n",
       " 'three kings': 467,\n",
       " 'thunderheart': 25,\n",
       " 'thx 1138': 536,\n",
       " 'ticker': 535,\n",
       " 'titanic': 533,\n",
       " 'to sleep with anger': 539,\n",
       " 'tombstone': 571,\n",
       " 'tomorrow never dies': 530,\n",
       " 'top gun': 487,\n",
       " 'total recall': 486,\n",
       " 'toy story': 538,\n",
       " 'traffic': 368,\n",
       " 'trainspotting': 106,\n",
       " 'transatlantic merry-go-round': 532,\n",
       " 'tremors': 485,\n",
       " 'tron': 363,\n",
       " 'trouble in paradise': 534,\n",
       " 'true believer': 484,\n",
       " 'true lies': 364,\n",
       " 'true romance': 361,\n",
       " 'twelve monkeys': 362,\n",
       " 'twin peaks: fire walk with me': 491,\n",
       " 'u turn': 121,\n",
       " 'u-turn': 109,\n",
       " 'unbreakable': 544,\n",
       " 'unforgiven': 543,\n",
       " 'vampyr': 454,\n",
       " 'verdict': 524,\n",
       " 'vertigo': 527,\n",
       " 'very bad things': 526,\n",
       " 'viridiana': 529,\n",
       " 'virtuosity': 528,\n",
       " 'wag the dog': 541,\n",
       " 'wall street': 540,\n",
       " 'watchmen': 176,\n",
       " 'waxwork': 185,\n",
       " 'what lies beneath': 184,\n",
       " 'what women want': 384,\n",
       " 'white angel': 378,\n",
       " 'white squall': 493,\n",
       " 'who framed roger rabbit': 278,\n",
       " \"who's your daddy?\": 377,\n",
       " 'wild at heart': 492,\n",
       " 'wild things': 183,\n",
       " 'wild wild west': 379,\n",
       " 'willow': 175,\n",
       " 'witness': 107,\n",
       " 'wonder boys': 94,\n",
       " 'x-men': 181,\n",
       " 'xxx': 177,\n",
       " 'young frankenstein': 182,\n",
       " 'zulu dawn': 180}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_name_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98e2a7653775d77c9ce70a978defbe19",
     "grade": false,
     "grade_id": "cell-f4005b2d38712fdb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 3 (Code Completion): Term Similarity\n",
    "Complete the function `top_terms`, which takes in the list of movie names, and returns the top matching tfidf terms from these movie transcripts. Consider doing an element-wise product of the movies' tfidf vectors. If all vectors have a high value for a particular term, then it is contributing to the cosine similarity for each (e.g. if both \"star wars\" and \"jurassic park\" both had high tfidf weights for \"fight,\" then this word would likely be a top_term for the two). After performing the element-wise product, find the indices that produce the highest values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f487ac77df59e5c207b4832e60c0d3f5",
     "grade": false,
     "grade_id": "top_terms",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def top_terms(movs, input_doc_mat, index_to_vocab, movie_name_to_index, top_k=10):\n",
    "    \"\"\"Returns a list of the top k similar terms (in order) between the\n",
    "        inputted movie transcripts.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    movs : str list (Length >= 2)\n",
    "        List of movie names \n",
    "    input_doc_mat : np.ndarray\n",
    "        The term document matrix of the movie transcripts. input_doc_mat[i][j] is the tfidf\n",
    "        of the movie i for the word j.\n",
    "    index_to_vocab : dict\n",
    "         A dictionary linking the index of a word (Key: int) to the actual word (Value: str). \n",
    "         Ex: {0: 'word_0', 1: 'word_1', .......}\n",
    "    movie_name_to_index : dict\n",
    "         A dictionary linking the movie name (Key: str) to the movie index (Value: int). \n",
    "         Ex: {'movie_0': 0, 'movie_1': 1, .......}\n",
    "    top_k : int\n",
    "        The k in the top k similar words to be returned. Ex: If top_k = 8, return top 8 similar words\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of the top k similar terms (in order) between the inputted movie transcripts\n",
    "    \"\"\"\n",
    "    dot_prod_sum = np.ones(len(index_to_vocab))\n",
    "\n",
    "    for i in range(len(movs)):\n",
    "        for j in range(i+1, len(movs)):\n",
    "\n",
    "            # Get the row index of mov1 and mov2 in the term-document matrix\n",
    "            mov1_idx = movie_name_to_index[movs[i]]\n",
    "            mov2_idx = movie_name_to_index[movs[j]]\n",
    "\n",
    "            # Get the vector representations of mov1 and mov2\n",
    "            mov1_vec = input_doc_mat[mov1_idx]\n",
    "            mov2_vec = input_doc_mat[mov2_idx]\n",
    "\n",
    "            # Compute the dot product between mov1 and mov2\n",
    "            dot_prod = mov1_vec *  mov2_vec\n",
    "\n",
    "            # Add the dot product to the dot_prod_sum\n",
    "            dot_prod_sum *= dot_prod\n",
    "\n",
    "    # Compute the top k similar words between mov1 and mov2\n",
    "    top_k_similar_words = []\n",
    "    for i in range(top_k):\n",
    "        max_idx = np.argmax(dot_prod_sum)\n",
    "        top_k_similar_words.append(index_to_vocab[max_idx])\n",
    "        dot_prod_sum[max_idx] = 0\n",
    "\n",
    "    return top_k_similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b399a3dd3dc4809242f6f2a93379c8b2",
     "grade": true,
     "grade_id": "top_terms_test",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten terms between: Star Wars and Jurassic Park\n",
      "======\n",
      "power\n",
      "force\n",
      "use\n",
      "control\n",
      "procedures\n",
      "afraid\n",
      "major\n",
      "gear\n",
      "guarantee\n",
      "thousand\n",
      "\n",
      "Top ten terms between: Star Wars and Star Trek: Generations\n",
      "======\n",
      "data\n",
      "sir\n",
      "ship\n",
      "star\n",
      "captain\n",
      "energy\n",
      "information\n",
      "starfleet\n",
      "weapon\n",
      "power\n",
      "\n",
      "Top ten terms between: Star Wars and Star Trek: Generations and Jurassic Park\n",
      "======\n",
      "power\n",
      "field\n",
      "afraid\n",
      "planet\n",
      "use\n",
      "control\n",
      "seven\n",
      "million\n",
      "attack\n",
      "risk\n"
     ]
    }
   ],
   "source": [
    "# This is an autograder test. Here we can test the function you just wrote above.\n",
    "\"\"\"Check that get_sim returns the correct output\"\"\"\n",
    "print(\"Top ten terms between: Star Wars and Jurassic Park\")\n",
    "print(\"======\")\n",
    "term_test_1 = top_terms(['star wars', 'jurassic park'], doc_by_vocab, index_to_vocab, movie_name_to_index)\n",
    "for term in term_test_1:\n",
    "    print(term)\n",
    "assert 'force' in term_test_1\n",
    "\n",
    "print(\"\")\n",
    "print(\"Top ten terms between: Star Wars and Star Trek: Generations\")\n",
    "term_test_2 = top_terms(['star wars', 'star trek: generations'], doc_by_vocab,index_to_vocab, movie_name_to_index)\n",
    "assert 'star' in term_test_2\n",
    "print(\"======\")\n",
    "for term in term_test_2:\n",
    "    print(term)\n",
    "    \n",
    "print(\"\")\n",
    "print(\"Top ten terms between: Star Wars and Star Trek: Generations and Jurassic Park\")\n",
    "term_test_3 = top_terms(['star wars', 'star trek: generations', 'jurassic park'], doc_by_vocab,index_to_vocab, movie_name_to_index)\n",
    "assert 'attack' in term_test_3\n",
    "print(\"======\")\n",
    "for term in term_test_3:\n",
    "    print(term)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3b (Free Response): Common terms interpretation\n",
    "\n",
    "\n",
    "In the cell below, state what you noticed about the common terms shared by the three movies in the test case ('star wars', 'star trek: generations', 'jurassic park'). Did the common terms represent some common themes, categories, or genres shared by these movies? \n",
    "<br>\n",
    "\n",
    "<div style=\"border-bottom: 4px solid #AAA; padding-bottom: 6px; font-size: 16px; font-weight: bold;\">Write your answer in the provided cell below</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "05f390f4fc642c361a28365eaf32a19f",
     "grade": false,
     "grade_id": "cell-f6d043750f734cf6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 4 (Code Completion): Similar Transcripts, Similar Movies w/ Cosine Sim\n",
    "\n",
    "Given your `get_sim` function, you can now compute how similar movies are to one another! Here, we will first precompute the similarity between every possible pair of movies, and store it in a movies-by-movies matrix. Given this matrix, for a given movie, it is possible to produce a ranking of how similar all other movies are to the given movie. For instance, we will see what movies are the most similar and dissimilar to \"star wars\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2bac8503fcd747bb79381942213fbe42",
     "grade": false,
     "grade_id": "build_movie_sims_cos",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def build_movie_sims_cos(n_mov, movie_index_to_name, input_doc_mat, movie_name_to_index, input_get_sim_method):\n",
    "    \"\"\"Returns a movie_sims matrix of size (num_movies,num_movies) where for (i,j):\n",
    "        [i,j] should be the cosine similarity between the movie with index i and the movie with index j\n",
    "        \n",
    "    Note: You should set values on the diagonal to 1\n",
    "    to indicate that all movies are trivially perfectly similar to themselves.\n",
    "    \n",
    "    Params: {n_mov: Integer, the number of movies\n",
    "             movie_index_to_name: Dictionary, a dictionary that maps movie index to name\n",
    "             input_doc_mat: Numpy Array, a numpy array that represents the document-term matrix\n",
    "             movie_name_to_index: Dictionary, a dictionary that maps movie names to index\n",
    "             input_get_sim_method: Function, a function to compute cosine similarity}\n",
    "    Returns: Numpy Array \n",
    "    \"\"\"\n",
    "    movie_sims = np.zeros((n_mov, n_mov))\n",
    "    for i in range(n_mov):\n",
    "        for j in range(n_mov):\n",
    "            movie_sims[i][j] = input_get_sim_method(movie_index_to_name[i], movie_index_to_name[j], input_doc_mat, movie_name_to_index)\n",
    "    return movie_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d6cbf0b3d16933f76d44c5d698f4355",
     "grade": false,
     "grade_id": "cell-ede81a4209974a0c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "movie_sims_cos = build_movie_sims_cos(num_movies, movie_index_to_name, doc_by_vocab, movie_name_to_index, get_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19b823c8445e3d61f8006203ea14786d",
     "grade": true,
     "grade_id": "movie_sims_cos_test",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is an autograder test. Here we can test the function you just wrote above.\n",
    "\"\"\"Check that build_movie_sims_cos returns the correct output\"\"\"\n",
    "assert type(movie_sims_cos) == np.ndarray\n",
    "assert movie_sims_cos.shape == (617,617)\n",
    "assert movie_sims_cos[15,15] == 1.0\n",
    "assert sum(movie_sims_cos[:,5]) > 40\n",
    "test_star_trek = movie_sims_cos[movie_name_to_index[\"star trek iii: the search for spock\"]][movie_name_to_index[\"star trek: the wrath of khan\"]]\n",
    "assert test_star_trek > 0.6 and test_star_trek < 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27215e07346fe49743430f78cdfb5974",
     "grade": false,
     "grade_id": "cell-ee2e54a7329b3a3d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 4b (Code Completion): Similar Transcripts, Similar Movies w/ Jaccard Sim\n",
    "\n",
    "For a baseline comparison, we will also consider the similarity between movies in terms of categories. Specifically, you'll notice that each movie is associated with a list of categories. One could ignore the transcripts *entirely* and say that the similarity between any two movies is the jaccard similarity of their category sets. While this is a very rough way to measure similarity, we will use it as a baseline for comparison with the linguistic methods.\n",
    "\n",
    "Hint: The keys of the dictionary are printed out in the same cell the data is loaded in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88546fb9e2b0918e9ec7489940485ace",
     "grade": false,
     "grade_id": "build_movie_sims_jac",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    \"\"\"Returns the jaccard similarity between two lists\n",
    "    Params: {list1: List, a list of elements\n",
    "             list2: List, a list of elements}\n",
    "    Returns: Float\n",
    "    \"\"\"\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    if len(set1.union(set2)) == 0:\n",
    "        return 0\n",
    "    return (len(set1.intersection(set2)) / (len(set1.union(set2))))\n",
    "\n",
    "\n",
    "def build_movie_sims_jac(n_mov, input_data):\n",
    "    \"\"\"Returns a movie_sims_jac matrix of size (num_movies,num_movies) where for (i,j) :\n",
    "        [i,j] should be the jaccard similarity between the category sets for movies i and j\n",
    "        such that movie_sims_jac[i,j] = movie_sims_jac[j,i]. \n",
    "        \n",
    "    Note: \n",
    "        Movies sometimes contain *duplicate* categories! You should only count a category once\n",
    "        \n",
    "        A movie should have a jaccard similarity of 1.0 with itself.\n",
    "    \n",
    "    Params: {n_mov: Integer, the number of movies,\n",
    "            input_data: List<Dictionary>, a list of dictionaries where each dictionary \n",
    "                     represents the movie_script_data including the script and the metadata of each movie script}\n",
    "    Returns: Numpy Array \n",
    "    \"\"\"\n",
    "    movie_sims_jac = np.zeros((n_mov, n_mov))\n",
    "    for i in range(n_mov):\n",
    "        for j in range(n_mov):\n",
    "            # print(input_data[i]['categories'])\n",
    "            movie_sims_jac[i][j] = jaccard_similarity(input_data[i]['categories'], input_data[j]['categories'])\n",
    "    return movie_sims_jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17b2c61fdec60225b044856be79c1fd6",
     "grade": false,
     "grade_id": "cell-9ffeab8de1a863dc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "movie_sims_jac = build_movie_sims_jac(num_movies,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a3859f190dcfc8e34e178cc527da6c9",
     "grade": true,
     "grade_id": "movie_sims_jac_test",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is an autograder test. Here we can test the function you just wrote above.\n",
    "\"\"\"Check that build_movie_sims_cos returns the correct output\"\"\"\n",
    "assert type(movie_sims_jac) == np.ndarray\n",
    "assert movie_sims_jac.shape == (617,617)\n",
    "assert sum(movie_sims_jac[:,5]) > 60 and sum(movie_sims_jac[:,5]) < 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b366e7bae9c50af0793d1f0d14189b4",
     "grade": false,
     "grade_id": "cell-4a540d60107ce945",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 4c (Free Response): Similar Transcripts, Similar Movies\n",
    "\n",
    "Using the `movie_sims_cos` and `movie_sims_jac` matrices you computed, we are now going to compare cosine vs. jaccard similarity by printing the 10 most similar (ignoring itself) and 10 most dissimilar movies to 'star wars'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60b5c59119a7eec8e0fffa2321b9d2a9",
     "grade": false,
     "grade_id": "cell-19eda7bcc6d614bb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def get_ranked_movies(mov, matrix):\n",
    "    \"\"\"\n",
    "    Return sorted rankings (most to least similar) of movies as \n",
    "    a list of two-element tuples, where the first element is the \n",
    "    movie name and the second element is the similarity score\n",
    "    \n",
    "    Params: {mov: String,\n",
    "             matrix: np.ndarray}\n",
    "    Returns: List<Tuple>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get movie index from movie name\n",
    "    mov_idx = movie_name_to_index[mov]\n",
    "    \n",
    "    # Get list of similarity scores for movie\n",
    "    score_lst = matrix[mov_idx]\n",
    "    mov_score_lst = [(movie_index_to_name[i], s) for i,s in enumerate(score_lst)]\n",
    "    \n",
    "    # Do not account for movie itself in ranking\n",
    "    mov_score_lst = mov_score_lst[:mov_idx] + mov_score_lst[mov_idx+1:]\n",
    "    \n",
    "    # Sort rankings by score\n",
    "    mov_score_lst = sorted(mov_score_lst, key=lambda x: -x[1])\n",
    "    \n",
    "    return mov_score_lst\n",
    "\n",
    "\n",
    "def print_top(mov, matrix, sim_type, k=10):\n",
    "    \"\"\"\n",
    "    Print the k most and least similar movies to 'star wars'\n",
    "    \n",
    "    Params: {mov: String,\n",
    "             matrix: np.ndarray,\n",
    "             sim_type: String,\n",
    "             k: Integer}\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    \n",
    "    mov_score_lst = get_ranked_movies(mov, matrix)\n",
    "    \n",
    "    print(\"Top {} most similar movies to {} [{}]\".format(k, 'star wars', sim_type))\n",
    "    print(\"======\")\n",
    "    for (mov, score) in mov_score_lst[:k]:\n",
    "        print(\"%.3f %s\" % (score, mov))\n",
    "\n",
    "    print()\n",
    "    \n",
    "    print(\"Top {} least similar movies to {} [{}]\".format(k, 'star wars', sim_type))\n",
    "    print(\"======\")\n",
    "    for (mov, score) in mov_score_lst[-k:][::-1]:\n",
    "        print(\"%.3f %s\" % (score, mov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96b7201032484f8c045b80734ba3b587",
     "grade": false,
     "grade_id": "cell-74bce35a04df44cd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most similar movies to star wars [cosine sim]\n",
      "======\n",
      "0.468 star wars: the empire strikes back\n",
      "0.406 star wars: episode vi - return of the jedi\n",
      "0.252 cool hand luke\n",
      "0.246 star trek: nemesis\n",
      "0.214 star trek: generations\n",
      "0.214 star trek: first contact\n",
      "0.211 the majestic\n",
      "0.205 star trek: insurrection\n",
      "0.203 hannibal\n",
      "0.197 dr. strangelove or: how i learned to stop worrying and love the bomb\n",
      "\n",
      "Top 10 least similar movies to star wars [cosine sim]\n",
      "======\n",
      "0.004 what women want\n",
      "0.010 the jazz singer\n",
      "0.013 the deer hunter\n",
      "0.014 five feet high and rising\n",
      "0.014 the rocky horror picture show\n",
      "0.015 the negotiator\n",
      "0.019 beavis and butt-head do america\n",
      "0.026 shock treatment\n",
      "0.027 spare me\n",
      "0.027 serial mom\n"
     ]
    }
   ],
   "source": [
    "print_top('star wars', movie_sims_cos, 'cosine sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f7c748ee36d21a9a7447f022cd7e5ba",
     "grade": false,
     "grade_id": "cell-c81f7651cd4500b3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most similar movies to star wars [jaccard]\n",
      "======\n",
      "1.000 krull\n",
      "1.000 the fantastic four\n",
      "1.000 fantastic four\n",
      "1.000 star wars: episode vi - return of the jedi\n",
      "0.800 superman ii\n",
      "0.800 superman iv: the quest for peace\n",
      "0.800 spider-man\n",
      "0.800 superman iii\n",
      "0.800 jurassic park\n",
      "0.800 ghostbusters ii\n",
      "\n",
      "Top 10 least similar movies to star wars [jaccard]\n",
      "======\n",
      "0.000 all the president's men\n",
      "0.000 all about eve\n",
      "0.000 grand hotel\n",
      "0.000 the grifters\n",
      "0.000 the graduate\n",
      "0.000 get shorty\n",
      "0.000 ghost ship\n",
      "0.000 ghost world\n",
      "0.000 storytelling\n",
      "0.000 dr. strangelove or: how i learned to stop worrying and love the bomb\n"
     ]
    }
   ],
   "source": [
    "print_top('star wars', movie_sims_jac, 'jaccard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "727bd3f9355e15034f38ae49cf55bf5c",
     "grade": false,
     "grade_id": "cell-25fa76331ae8813d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "In the cell below, analyze the most similar and least similar results above for both cosine similarity and jaccard similarity. Please comment on how well (or poorly) you think both of the similarity measures performed. Do these results make sense to you? Why are certain movies ranked more similar to Star Wars in one similarity measure than the other one?\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"border-bottom: 4px solid #AAA; padding-bottom: 6px; font-size: 16px; font-weight: bold;\">Write your answer in the provided cell below</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "492dc43965f52cf732cc12e3e6994dd8",
     "grade": true,
     "grade_id": "most_least_sim_movies_ans",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d8547781d026464d35b7493cf646ba4",
     "grade": false,
     "grade_id": "cell-40c993e89a549adb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<div style=\"border-bottom: 4px solid #AAA; padding-bottom: 6px; font-size: 16px; font-weight: bold;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b020e79daab508e799f1c32202354fa7",
     "grade": false,
     "grade_id": "cell-8f564d9e0d9278b3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 5 (Code Completion): Evaluating our rankings with precision-recall curves\n",
    "\n",
    "Given that we are able to produce a most-to-least similar ranking of all other movies given all other movies, we can now ask the question: \"How good are our rankings?\"\n",
    "\n",
    "For this part, we will be using the following (query, [related movie list]) pairs for you to evaluate against. We will treat these data as ground truth. More generally, you could imagine that these \"ground truths\" result from aggregated user feedback from a movie recomendation system like Netflix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1991802065e9d32a6f2f5ca7b6c5a7f",
     "grade": false,
     "grade_id": "cell-d0af2bf1d4f220ea",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "queries = [('the matrix', ['the bourne supremacy',\n",
    "                           'being john malkovich',\n",
    "                           'smoke',\n",
    "                           'erin brockovich',\n",
    "                           'an officer and a gentleman',\n",
    "                           'smokin\\' aces',\n",
    "                           'pitch black',\n",
    "                           'out of sight',\n",
    "                           'clerks.',\n",
    "                           'xxx',\n",
    "                           'the x files',\n",
    "                          ]),\n",
    "           ('star wars',  ['star wars: the empire strikes back',\n",
    "                            'star wars: episode vi - return of the jedi',\n",
    "                            'indiana jones and the last crusade',\n",
    "                            'indiana jones and the temple of doom',\n",
    "                            'jurassic park',\n",
    "                            'the lost world: jurassic park',\n",
    "                            'jurassic park iii',\n",
    "                            'star trek v: the final frontier',\n",
    "                            'star trek: the motion picture',\n",
    "                            'star trek: first contact',\n",
    "                            'star trek vi: the undiscovered country',\n",
    "                            'star trek iv: the voyage home',\n",
    "                            'the majestic',\n",
    "                            'hannibal',\n",
    "                            'star trek: insurrection',\n",
    "                            'dr. strangelove or: how i learned to stop worrying and love the bomb'\n",
    "                          ]),\n",
    "          ('a nightmare on elm street', ['a nightmare on elm street part 2: freddy\\'s revenge',\n",
    "                                         'a nightmare on elm street: the dream child',\n",
    "                                         'cruel intentions',\n",
    "                                         'erin brockovich',\n",
    "                                         'hellraiser: hellseeker',\n",
    "                                         'little nicky',\n",
    "                                        ]),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "336eeb0838b4d3a0b7c869e4fb1d1b55",
     "grade": false,
     "grade_id": "cell-31a990e9921e58ca",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "To answer our question, we will now look at two ways of evaluating our rankings:\n",
    "1. Precision vs. Recall plots\n",
    "\n",
    "2. An evaluation statistic called Mean Average Precision\n",
    "\n",
    "To start off, **complete the `precision_recall` function below.**\n",
    "To recap, `precision @ K` measures the precision in the subset of documents that were retrieved _up to_ an index $K$, and `recall @ K` is defined similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5259a7ead11402825cab8e3f18f75924",
     "grade": false,
     "grade_id": "precision_recall",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def precision_recall(ranking_in, relevant):\n",
    "    \"\"\"\n",
    "    Returns lists of precision and recall at different k values\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ranking_in : str list \n",
    "        List with sorted ranking of movies (movie names), starting with the most similar, and ending\n",
    "        with the least similar.\n",
    "    relevant : str list\n",
    "        List of movies (movie names) relevant to the original query\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple: (np.ndarray, np.ndarray)\n",
    "        Returns tuple such that tuple[0] is numpy array of precision at different k values and \n",
    "        tuple[1] is numpy array of recall at different k values. \n",
    "    \n",
    "        tuple[0] -> precision: numpy array of length equal to the length+1 of ranking_in, where \n",
    "        precision[k] = the precision@k. Leave precision[0] to be 0.\n",
    "        \n",
    "        tuple[1] -> recall: numpy array of length equal to the length+1 of ranking_in, where \n",
    "        recall[k] = the recall@k. Leave recall[0] to be 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    precision = np.zeros(len(ranking_in)+1)\n",
    "    recall = np.zeros(len(ranking_in)+1)\n",
    "    for k in range(1, len(ranking_in)+1):\n",
    "        precision[k] = len(set(ranking_in[:k]) & set(relevant)) / k\n",
    "        recall[k] = len(set(ranking_in[:k]) & set(relevant)) / len(relevant)\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5585f1568ed73ed95b5f05f7fc56bf5e",
     "grade": true,
     "grade_id": "precision_recall_test",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is an autograder test. Here we can test the function you just wrote above.\n",
    "\"\"\"Check that precision_recall returns the correct output\"\"\"\n",
    "query, rel_movs = queries[1]\n",
    "ranked_movs = [m for m,_ in get_ranked_movies(query, movie_sims_cos)]\n",
    "precision, recall = precision_recall(ranked_movs, rel_movs)\n",
    "\n",
    "assert precision[0] == 0\n",
    "assert recall[0] == 0\n",
    "assert precision.shape == (617,)\n",
    "assert recall.shape == (617,)\n",
    "assert sum(precision) > 48 and sum(precision) < 54\n",
    "assert sum(recall) > 505 and sum(recall) < 511\n",
    "assert precision[300] > 0.04 and precision[300] < 0.05\n",
    "assert recall[300] > 0.8 and recall[300] < 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1d48a3c666a3f974b253c822662640f",
     "grade": false,
     "grade_id": "cell-ea997339be861abf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Plotting Precision-Recall Curves\n",
    "\n",
    "Below, we have provided the code that uses matplotlib to create a recall (x-axis) vs. precision (y-axis) plot, plotting each of the 3 ground truth queries as seperate lines on the plot. For each query, we consider all N-1 movies other than the query itself when computing the ranking. The label of each line is the ground truth query. \n",
    "\n",
    "It's worth noting that considering precision/recall curves like this on the query level is a bit odd. In general, given more supervised data, one would compute aggregate precision/recall curves over a large number of ground truths. In this way, each line would represent a different information retrieval algorithm's performance over the test set of queries. However, we will be somewhat unorthodox here and plot one curve per query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7193a79d106c862dc4cc5ce948f8265a",
     "grade": false,
     "grade_id": "cell-9b33baf2399a497f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall(matrix, xlim, ylim):\n",
    "    \"\"\"Plots the precision-recall curve given the similarity matrix\n",
    "    \n",
    "    Params: {matrix: np.ndarray,\n",
    "             xlim: List,\n",
    "             ylim: List}\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    for query, rel_movs in queries:\n",
    "        ranked_movs = [m for m,_ in get_ranked_movies(query, matrix)]\n",
    "        precision, recall = precision_recall(ranked_movs, rel_movs)\n",
    "        plt.plot(recall, precision)\n",
    "\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    plt.legend([q[0] for q in queries])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc81ac91b2a8dee50a0862c905eb1411",
     "grade": false,
     "grade_id": "cell-db5371070c5ffeac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 5b (Free Response): Cosine Similarity Plot Analysis\n",
    "\n",
    "Run the code below to show the precision-recall curve for our three movie queries using cosine similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a8ffa0a4ddd3c71496675f2e41af392",
     "grade": false,
     "grade_id": "cell-0c56de23d0985e7c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cosine Similarity Plot\n",
    "plot_precision_recall(movie_sims_cos, [0,1.1], [0,1.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7be7451b1942661fc2de41fa4c80f72e",
     "grade": false,
     "grade_id": "cell-ad9ada38bdd57133",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Looking at the cosine similarity plot above, make some observations about why you're seeing what you're seeing. What does the plot reveal about the performance of the cosine similarity method for the given queries? Include observations on what worked well, what didn't, and how you've arrived at these conclusions. \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<div style=\"border-bottom: 4px solid #AAA; padding-bottom: 6px; font-size: 16px; font-weight: bold;\">Write your answer in the provided cell below</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2871fdff96652e713bd2dead84b9458",
     "grade": true,
     "grade_id": "cos_sim_precision_recall_ans",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "036cfd147c5527c73dc51a3eebd4c23f",
     "grade": false,
     "grade_id": "cell-f8fb289995e9b6b2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<div style=\"border-bottom: 4px solid #AAA; padding-bottom: 6px; font-size: 16px; font-weight: bold;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d51743e8abf41358a9bc7a8fc20846e7",
     "grade": false,
     "grade_id": "cell-bbd3cce37bf8d9d4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 5c (Free Response): Jaccard Similarity Plot Analysis\n",
    "\n",
    "Run the code below to show the precision-recall curve for our three movie queries using jaccard similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1450cc4bb725dc1e468be421dee90c43",
     "grade": false,
     "grade_id": "cell-bf2fe6a0cfbd5303",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Jaccard Similarity Plot\n",
    "plot_precision_recall(movie_sims_jac, [0,1.1], [0,0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a370c5bc44e71b68489381b8dc26602",
     "grade": false,
     "grade_id": "cell-72aaf601ea602b3e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Looking at the jaccard similarity plot above,  make some observations about why you're seeing what you're seeing. What does the plot reveal about the performance of the jaccard similarity method for the given queries? Include observations on what worked well, what didn't, and how you've arrived at these conclusions. \n",
    "\n",
    "<div style=\"border-bottom: 4px solid #AAA; padding-bottom: 6px; font-size: 16px; font-weight: bold;\">Write your answer in the provided cell below</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a38b9f503263aef130792ee40cabff73",
     "grade": true,
     "grade_id": "jaccard_precision_recall_ans",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b7759312a08df93610d59d55ca97962",
     "grade": false,
     "grade_id": "cell-750e4e70738c4fc0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<div style=\"border-bottom: 4px solid #AAA; padding-bottom: 6px; font-size: 16px; font-weight: bold;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6a4044738ea5261ba5ee1d36f47392b6",
     "grade": false,
     "grade_id": "cell-cc3dc0d1770e67ea",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 5d (Free Response): Cosine Sim vs Jaccard Sim Plot Comparison\n",
    "\n",
    "Now that you've observed the plots for both cosine similarity and jaccard similarity, please answer the following two questions:\n",
    "\n",
    "1. Which system performs better, in general?\n",
    "2. Which query was the most problematic in each case?\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"border-bottom: 4px solid #AAA; padding-bottom: 6px; font-size: 16px; font-weight: bold;\">Write your answer in the provided cell below</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf0dc9000beec71c737bee0586339cf3",
     "grade": true,
     "grade_id": "cos_sim_jaccard_plot_ans",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4331352beab43da0c14cadfd4ee4b1cf",
     "grade": false,
     "grade_id": "cell-e00b96543d525387",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<div style=\"border-bottom: 4px solid #AAA; padding-bottom: 6px; font-size: 16px; font-weight: bold;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "856dbff088246de017680aadadc49b90",
     "grade": false,
     "grade_id": "cell-90e94cb41383c723",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 5e (Code Completion): Calculating F-score Values\n",
    "\n",
    "Now that you have seen the precison-recall, we will calculate the F-score foreach of the queries and see if they reveal any new information. As a reminder, the formuala for calculating the F-score is given below.\n",
    "\n",
    "$$F-score = \\frac{2}{\\frac{1}{Precision} + \\frac{1}{Recall}}$$ \n",
    "\n",
    "Note: If Precision or Recall is 0 we will just state that the fscore is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fda1671b4e0cefc8895d1d0549f372d",
     "grade": false,
     "grade_id": "compute_fscore",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_fscore(precision, recall):\n",
    "    \"\"\"\n",
    "    Returns lists of f-score values at different k values, where fscore[k] = the fscore@k\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    precision : np.ndarray\n",
    "        numpy array of precision values at different k values, where precision[k] = the\n",
    "        precision@k.\n",
    "    recall : np.ndarray\n",
    "        numpy array of recall values at different k values, where recall[k] = the\n",
    "        recall@k.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Returns a numpy array of length equal to the length of the precision (and recall) parameter \n",
    "        array, where fscore[k] = the fscore@k.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b3df8f59d3ca23a3a4079b0132b5d34",
     "grade": true,
     "grade_id": "compute_fscore_test",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is an autograder test. Here we can test the function you just wrote above.\n",
    "\"\"\"Check that precision_recall returns the correct output\"\"\"\n",
    "query, rel_movs = queries[1]\n",
    "ranked_movs = [m for m,_ in get_ranked_movies(query, movie_sims_cos)]\n",
    "precision, recall = precision_recall(ranked_movs, rel_movs)\n",
    "fscore = compute_fscore(precision, recall)\n",
    "\n",
    "assert fscore[0] == 0\n",
    "assert fscore.shape == (617,)\n",
    "assert recall.shape == (617,)\n",
    "assert sum(fscore) > 60 and sum(precision) < 100\n",
    "assert fscore[300] > 0.08 and precision[300] < 0.09\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad9471bdd48f4ce392f9e4a874e8f67f",
     "grade": false,
     "grade_id": "cell-5fa79dd748b5b0a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_fscore(matrix):\n",
    "    \"\"\"Plots the fscore curve given the similarity matrix\n",
    "    \n",
    "    Params: {matrix: np.ndarray}\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    query, rel_movs = queries[1]\n",
    "    ranked_movs = [m for m,_ in get_ranked_movies(query, movie_sims_cos)]\n",
    "\n",
    "    for query, rel_movs in queries:\n",
    "        ranked_movs = [m for m,_ in get_ranked_movies(query, matrix)] \n",
    "        precision, recall = precision_recall(ranked_movs, rel_movs)\n",
    "        fscore = compute_fscore(precision, recall)\n",
    "        plt.plot(range(1,len(fscore)+1), fscore)\n",
    "\n",
    "    plt.xlabel(\"K\")\n",
    "    plt.ylabel(\"Fscore\")\n",
    "    plt.legend([q[0] for q in queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "674df6e5ca3c45f65c6a295f649de65d",
     "grade": false,
     "grade_id": "cell-c4d2788c9a5990f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_fscore(movie_sims_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1108aaeae76be83aaf0c1f9f9f7f6abf",
     "grade": false,
     "grade_id": "cell-1787e98b89f4df33",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_fscore(movie_sims_jac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a95a0a16e592b89a334afc547b61b33",
     "grade": false,
     "grade_id": "cell-84d89d951f55f771",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 5f (Free Response): Cosine Sim vs Jaccard Sim Fscore Plot Comparison\n",
    "\n",
    "Now that you've observed the fscore plots for both cosine similarity and jaccard similarity, please answer the following three questions:\n",
    "\n",
    "1. In what ways do the F-score curves provide more or different information about the retrievals compared to the precision-recall graphs?\n",
    "2. Are there any queries for which the F-score curves suggest different rankings of movies than the precision-recall graphs? If so, which queries and what are the differences?\n",
    "3. How would you interpret the shape of the F-score curves for a given query? What does a flat curve or a steeply increasing curve indicate about the rankings?\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"border-bottom: 4px solid #AAA; padding-bottom: 6px; font-size: 16px; font-weight: bold;\">Write your answer in the provided cell below</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da2717c0a6c8ef06235d9f425b6b4d89",
     "grade": true,
     "grade_id": "compute_fscore_ans",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4324c3d7a35e61ff0a6239d6c691eadd",
     "grade": false,
     "grade_id": "cell-c28dc48be231ec6f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div style=\"border-bottom: 4px solid #AAA; padding-bottom: 6px; font-size: 16px; font-weight: bold;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "646bc21b152ff20d6574ffbf30748c24",
     "grade": false,
     "grade_id": "cell-109cf3608e5d5c15",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Evaluating our rankings with Mean Average Precision\n",
    "\n",
    "While precision/recall curves are a good tool to visualize how well our rankings are performing, in some contexts, it is ideal to come up with a single number that characterizes how well our ranking system is doing over all ground-truth queries. A commonly used statistic for ranking systems is _Mean Average Precision_. To compute this value, first, one must compute the average precision for each query and subsequent ranking output by the system. Next, one averages these values. We've filled in functions for both `average_precision` and `mean_average_precision` for you. At the end of this section, run the provided code, which will give you a single number that evaluates the performance of each ranking system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea7b2d040521cef73e39c4e1487e75f7",
     "grade": false,
     "grade_id": "cell-d87b0cba955da30c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def average_precision(ranking_in, relevant):\n",
    "    '''\n",
    "    Arguments:\n",
    "        ranking_in: sorted ranking of movies, starting with the most most similar, and ending\n",
    "        with the least similar.\n",
    "        \n",
    "        relevant: iterable of movies relevant to the original query\n",
    "        \n",
    "    Returns:\n",
    "        average_precision: float corresponding to the AP statistic for this ranking and\n",
    "        this set of relevant docuemnts.\n",
    "    '''\n",
    "    rel_rank = sorted([ranking_in.index(r)+1 for r in relevant])\n",
    "    return np.mean([(i+1)*1./(r) for i, r in enumerate(rel_rank)])\n",
    "    \n",
    "    \n",
    "def mean_average_precision(queries_in, sims_mat):\n",
    "    '''\n",
    "    Arguments:\n",
    "        queries_in: a list of (query, [relevant documents]) pairs, representing the queries we\n",
    "        want to evaluate our ranking system against\n",
    "    \n",
    "        sims_mat: a movie by movie numpy array, where sims_mat[i,j] = sims_mat[j,i] = the similarity\n",
    "        of movies i and j\n",
    "    \n",
    "    Returns:\n",
    "        mean_average_precision: float corresponding to the average AP statistic for the input queries\n",
    "        and the similarity matrix\n",
    "    '''\n",
    "    rankings = [[movie_index_to_name[i] for i in np.argsort(sims_mat[movie_name_to_index[q],:])[::-1] if movie_index_to_name[i] != q]\n",
    "                for q,_ in queries]\n",
    "    aps = []\n",
    "    for i, results in enumerate(rankings):\n",
    "        ap = average_precision(results, queries_in[i][1])\n",
    "        aps.append(ap)\n",
    "        print(\"Query name:\", queries_in[i][0], \"//\", \"Avg. Precision: {:.3f}\".format(ap))\n",
    "    mean_avg_precision = 1.0 * sum(aps)/len(queries_in)\n",
    "    print(\"[Mean Average Precision: {:.3f}]\".format(mean_avg_precision))\n",
    "    return mean_avg_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83b13b209b3881c2c44da3cd2cede3b5",
     "grade": false,
     "grade_id": "cell-2edbcf40432cac11",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== cosine_sim with tfidf features ===\")\n",
    "mean_average_precision(queries, movie_sims_cos)\n",
    "print()\n",
    "print(\"=== jacc_sim ===\")\n",
    "mean_average_precision(queries, movie_sims_jac)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8eb3125015d5204dce7d9b7ad9f743d3",
     "grade": false,
     "grade_id": "cell-d7af38aaebdd8447",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Rocchio Algorithm\n",
    "\n",
    "Great -- we have a baseline evaluation for how well our vector space tfidf information retrevial system does! Now, it is our job to do something better. Here, we will implement the Rocchio Algorithm and use it for pseudo relevance feedback.\n",
    "\n",
    "This is Rocchioâs query update rule for relevance feedback:\n",
    "\n",
    "$$\\overrightarrow{{q}_1} = a * \\overrightarrow{{q}_0} + b*\\frac{1}{|D_r|}\\sum_{d \\in D_r}{\\overrightarrow{d}}-c*\\frac{1}{|D_{nr}|}\\sum_{d \\in D_{nr}}{\\overrightarrow{d}}$$ \n",
    "\n",
    "In the above, $\\overrightarrow{{q}_0}$ is the initial query, $\\overrightarrow{{q}_1}$ is the updated query, $D_r$ is the set of relevant documents and $D_{nr}$ is the set of non-relevant documents. $a$, $b$, and $c$ are the update weights that correspond to the original query, the relevant queries, and the irrelevant queries, respectively. If after the update, there are negative values in $\\overrightarrow{{q}_1}$, they are set to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b6debc032cfa61f892ba98d7d467a987",
     "grade": false,
     "grade_id": "cell-31cb35d1cc54c927",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 6 (Code Completion): Rocchio\n",
    "Your job here is to implement the Rocchio Algorithm for relevance feedback. This function will test your understanding of how numpy arrays interact with variable types. For example, a + b where a is a python float and b is a numpy array will return a numpy array where each element of b has been shifted by a. While this particular function may or may not be needed to implement rocchio, it can be *very* helpful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2516265e51c6983dff8182d8b85d2abc",
     "grade": false,
     "grade_id": "rocchio",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def rocchio(query, relevant, irrelevant, input_doc_matrix, \\\n",
    "            movie_name_to_index,a=.3, b=.3, c=.8, clip = True):\n",
    "    \"\"\"Returns a vector representing the modified query vector. \n",
    "    \n",
    "    Note: \n",
    "        If the `clip` parameter is set to True, the resulting vector should have \n",
    "        no negatve weights in it!\n",
    "        \n",
    "        Also, be sure to handle the cases where relevant and irrelevant are empty lists.\n",
    "        \n",
    "    Params: {query: String (the name of the movie being queried for),\n",
    "             relevant: List (the names of relevant movies for query),\n",
    "             irrelevant: List (the names of irrelevant movies for query),\n",
    "             input_doc_matrix: Numpy Array,\n",
    "             movie_name_to_index: Dict,\n",
    "             a,b,c: floats (weighting of the original query, relevant queries,\n",
    "                             and irrelevant queries, respectively),\n",
    "             clip: Boolean (whether or not to clip all returned negative values to 0)}\n",
    "    Returns: Numpy Array \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f54007ee3b71da9483009617238e25d8",
     "grade": false,
     "grade_id": "cell-02d9c6563f21a92a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Before we use the Rocchio algorithm for understanding pseduo-relevance feedback, we'll do a reality check and make sure that our implementation can improve performance on our existing queries. To augment our analysis, movie guru Ilan has also provided you with a list of irrelevant queries for each of our test queries. You'll notice that the irrelevant queries for each of the test queries are quite similar. This is because it's much more common for a pair of movies to be irrelevant, rather than relevant. In fact, it's not uncommon that *all* queries that are not relevant are *assumed to be irrelevant.*\n",
    "\n",
    "Here, though, we'll just use this small subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df949ee25a37a54ea7add3ab4d6433e7",
     "grade": false,
     "grade_id": "cell-b606d1e4ff38c062",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "irrelevant  = [('the matrix', ['lone star',\n",
    "                               '2001: a space odyssey',\n",
    "                               'wall street',\n",
    "                               'the elephant man',\n",
    "                               'eternal sunshine of the spotless mind',\n",
    "                              'suburbia',\n",
    "                               'taking sides',\n",
    "                               'lake placid'\n",
    "                              ]),\n",
    "               ('star wars',  ['lone star',\n",
    "                               '2001: a space odyssey',\n",
    "                               'wall street',\n",
    "                               'the elephant man',\n",
    "                               'eternal sunshine of the spotless mind',\n",
    "                              'suburbia',\n",
    "                              'taking sides',\n",
    "                              'lake placid']),\n",
    "               ('a nightmare on elm street', ['lone star',\n",
    "                               '2001: a space odyssey',\n",
    "                               'wall street',\n",
    "                               'the elephant man',\n",
    "                               'eternal sunshine of the spotless mind',\n",
    "                                'suburbia',\n",
    "                                'taking sides',\n",
    "                                'lake placid']),]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20e32678e4d9f33040c2888421547e00",
     "grade": true,
     "grade_id": "rocchio_test",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is an autograder test. Here we can test the function you just wrote above.\n",
    "\"\"\"Check that rocchio returns the correct output\"\"\"\n",
    "query_vector = rocchio(\"the matrix\",[],irrelevant[0][1],doc_by_vocab,movie_name_to_index)\n",
    "query_vector2 = rocchio(\"star wars\",[],irrelevant[1][1],doc_by_vocab,movie_name_to_index)\n",
    "assert type(query_vector) == np.ndarray\n",
    "assert type(query_vector2) == np.ndarray\n",
    "assert sum(query_vector) > 3 and sum(query_vector) < 4\n",
    "assert sum(query_vector2) > 2 and sum(query_vector2) < 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2a6110b1d3c8b84d6ff7c352e6ad03e",
     "grade": false,
     "grade_id": "cell-48508f719504108e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 7 (Code Completion): Leveraging Rocchio\n",
    "Your job is to leverage rocchio to return the top 10 highest ranked movies for each query, where the query vector is updated with rocchio. \n",
    "Return the dictionary with in the following format:\n",
    "```\n",
    "{'the matrix': [movie1,movie2,...,movie10],\n",
    " 'star wars': [movie1,movie2,...,movie10],\n",
    " 'a nightmare on elm street': [movie1,movie2,...,movie10]}\n",
    "```\n",
    "\n",
    "\n",
    "Note that the query itself should be excluded from the rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0c1da39e25d4df4ebb853bdac853bab",
     "grade": false,
     "grade_id": "top_10_with_rocchio",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def top_10_with_rocchio(relevant_in, irrelevant_in, input_doc_matrix, \\\n",
    "            movie_name_to_index,movie_index_to_name,input_rocchio):\n",
    "    \"\"\"Returns a dictionary in the following format:\n",
    "    {\n",
    "        'the matrix': [movie1,movie2,...,movie10],\n",
    "        'star wars': [movie1,movie2,...,movie10],\n",
    "        'a nightmare on elm street': [movie1,movie2,...,movie10]\n",
    "    }\n",
    "    \n",
    "    Note: \n",
    "        You can assume that relevant_in[i][0] = irrelevant_in[i][0] \n",
    "        (i.e. the queries are in the same order). \n",
    "        \n",
    "        You should use the default rocchio parameters.\n",
    "        \n",
    "        You should NOT return the query itself in the list of most common\n",
    "        movies.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    relevant_in : (query: str, [relevant documents]: str list) list \n",
    "        List of tuples of the form:\n",
    "        tuple[0] = name of movie being queried (str), \n",
    "        tuple[1] = list of names of the relevant movies to the movie being queried (str list).\n",
    "    irrelevant_in : (query: str, [irrelevant documents]: str list) list \n",
    "        The same format as relevant_in except tuple[1] contains list of irrelevant movies instead.\n",
    "    input_doc_matrix : np.ndarray\n",
    "        The term document matrix of the movie transcripts. input_doc_mat[i][j] is the tfidf\n",
    "        of the movie i for the word j.\n",
    "    movie_name_to_index : dict\n",
    "         A dictionary linking the movie name (Key: str) to the movie index (Value: int). \n",
    "         Ex: {'movie_0': 0, 'movie_1': 1, .......}\n",
    "    movie_index_to_name : dict\n",
    "         A dictionary linking the movie index (Key: int) to the movie name (Value: str). \n",
    "         Ex: {0:'movie_0', 1:'movie_1', .......}\n",
    "    input_rocchio: function\n",
    "        A function implementing the rocchio algorithm. Refer to Q6 for the function \n",
    "        input parameters. Make sure you use the function's default parameters as \n",
    "        much as possible.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Returns the top ten highest ranked movies for each query in the format described above.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "114074f4c56c643d723dad186140b43b",
     "grade": false,
     "grade_id": "cell-e03266a4304b7776",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "movie_recommend_with_rocchio = top_10_with_rocchio(queries, irrelevant,\\\n",
    "                                                  doc_by_vocab,movie_name_to_index,\\\n",
    "                                                  movie_index_to_name,rocchio)\n",
    "for k,v in movie_recommend_with_rocchio.items():\n",
    "    print(k)\n",
    "    print(\"=\"*len(k))\n",
    "    [print(a) for a in v]\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e992d6b030d64c12e7b0215aeff77387",
     "grade": true,
     "grade_id": "top_10_with_rocchio_test",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is an autograder test. Here we can test the function you just wrote above.\n",
    "\"\"\"Check that top_10_with_rocchio returns the correct output\"\"\"\n",
    "assert type(movie_recommend_with_rocchio) == dict\n",
    "assert \"the x files\" in movie_recommend_with_rocchio[\"the matrix\"]\n",
    "assert \"star wars: the empire strikes back\" in movie_recommend_with_rocchio[\"star wars\"]\n",
    "assert \"a nightmare on elm street 3: dream warriors\" in \\\n",
    "    movie_recommend_with_rocchio[\"a nightmare on elm street\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1b31d57349b2a111a1652df3d259ddb7",
     "grade": false,
     "grade_id": "cell-6941eafd9a21a487",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 7b (Code Completion): Leveraging Rocchio\n",
    "Your job is to implement `mean_average_precision_rocchio` below, to compute MAP using the Rocchio-updated query vectors.\n",
    "\n",
    "Your function should call `rocchio` and `average_precision`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bb57b9631c3c437c6b45378d65de93b",
     "grade": false,
     "grade_id": "mean_average_precision_rocchio",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def mean_average_precision_rocchio(relevant_in, irrelevant_in, input_doc_matrix, \\\n",
    "            movie_name_to_index, movie_index_to_name, input_rocchio):\n",
    "    \"\"\"Returns a float corresponding to the mean AP statistic for the Rocchio-updated input queries\n",
    "        and the similarity matrix\n",
    "    Note: \n",
    "        You can assume that relevant_in[i][0] = irrelevant_in[i][0] \n",
    "        (i.e. the queries are in the same order). \n",
    "        \n",
    "        You should use the default rocchio parameters.\n",
    "        \n",
    "        You should NOT include the query itself in the list of most common\n",
    "        movies.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    relevant_in : (query: str, [relevant documents]: str list) list \n",
    "        List of tuples of the form:\n",
    "        tuple[0] = name of movie being queried (str), \n",
    "        tuple[1] = list of names of the relevant movies to the movie being queried (str list).\n",
    "    irrelevant_in : (query: str, [irrelevant documents]: str list) list \n",
    "        The same format as relevant_in except tuple[1] contains list of irrelevant movies instead.\n",
    "    input_doc_matrix : np.ndarray\n",
    "        The term document matrix of the movie transcripts. input_doc_mat[i][j] is the tfidf\n",
    "        of the movie i for the word j.\n",
    "    movie_name_to_index : dict\n",
    "         A dictionary linking the movie name (Key: str) to the movie index (Value: int). \n",
    "         Ex: {'movie_0': 0, 'movie_1': 1, .......}\n",
    "    movie_index_to_name : dict\n",
    "         A dictionary linking the movie index (Key: int) to the movie name (Value: str). \n",
    "         Ex: {0:'movie_0', 1:'movie_1', .......}\n",
    "    input_rocchio: function\n",
    "        A function implementing the rocchio algorithm. Refer to Q6 for the function \n",
    "        input parameters. Make sure you use the function's default parameters as \n",
    "        much as possible.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Returns a float corresponding to the mean AP statistic for the Rocchio-updated input queries\n",
    "        and the similarity matrix\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "838d5924b92c8bf7eeac6a76210878a7",
     "grade": true,
     "grade_id": "mean_average_precision_rocchio_test",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is an autograder test. Here we can test the function you just wrote above.\n",
    "\"\"\"Check that mean_average_precision_rocchio returns the correct output\"\"\"\n",
    "mean_average_precision = mean_average_precision_rocchio(queries, irrelevant,\\\n",
    "                                                  doc_by_vocab,movie_name_to_index,\\\n",
    "                                                  movie_index_to_name,rocchio)\n",
    "assert mean_average_precision > 0.60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a053640e658f1b5f79264d28c1cdfddd",
     "grade": false,
     "grade_id": "cell-798587bcc78c618e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The Rocchio addition to the system clearly adds a much larger level of precision as you are doing query\n",
    "modification that is based on relevant and irrelevant documents that are passed in. With the revision\n",
    "of this query this increases the search engine's recall, as well as the precision.\n",
    "\n",
    "**Note:**\n",
    "While our performance increased, it shouldn't be surprising that this is the case. At a high level, here is what we did: we took our original query vectors and moved them slightly closer to the \"ground truth\" relevant documents, and then used mean average precision to find that, indeed, the new query vector was closer to the true \"ground truth\" vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "037cf4f5b90018d3778228129c4638cd",
     "grade": false,
     "grade_id": "cell-6ecc56131c012635",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 8 (Free Response): Biggest Losses\n",
    "\n",
    "However, it is fun to see what words were given more or less weight for a given query according to the Rocchio modified query vector. Understand and run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85f4da47e3be62a3e859d601b9754eba",
     "grade": false,
     "grade_id": "cell-95e722cbecf45266",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "q_o = doc_by_vocab[movie_name_to_index[queries[0][0]],:]\n",
    "q_m = rocchio(queries[0][0], queries[0][1], irrelevant[0][1],doc_by_vocab,movie_name_to_index)\n",
    "diffs = q_m-q_o\n",
    "args_diffs = np.argsort(diffs)\n",
    "losses = args_diffs[:10]\n",
    "print(\"Biggest losses:\")\n",
    "for l in losses:\n",
    "    print(\"{}:{:.3f}\".format(index_to_vocab[l], diffs[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "743ac3acdc1272714f6ff26fc7fc7001",
     "grade": false,
     "grade_id": "cell-4c62999080fa04a9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "In the cell below, explain what the code is doing and what the findings show\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"border-bottom: 4px solid #AAA; padding-bottom: 6px; font-size: 16px; font-weight: bold;\">Write your answer in the provided cell below</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4121d5871bec3ace4affa352fbe3e56a",
     "grade": true,
     "grade_id": "biggest_loss_ans",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95736a0938d1b2e30c339c221560f6d8",
     "grade": false,
     "grade_id": "cell-78671e18533b1ee9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<div style=\"border-bottom: 4px solid #AAA; padding-bottom: 6px; font-size: 16px; font-weight: bold;\"></div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "LangInfo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "98ca369906f7b70fe64afc73e530e378539d08b0e41e494e07f1eb5e7a313c26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
